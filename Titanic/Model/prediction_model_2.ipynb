{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><u><b><h1 style=\"color:Red;\">Titanic : Machine Learning from Disaster</u></b></h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8411214953271028\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.88      0.87        65\n",
      "         1.0       0.80      0.79      0.80        42\n",
      "\n",
      "    accuracy                           0.84       107\n",
      "   macro avg       0.83      0.83      0.83       107\n",
      "weighted avg       0.84      0.84      0.84       107\n",
      "\n",
      "Confusion Matrix:\n",
      "[[57  8]\n",
      " [ 9 33]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_19188\\3452088656.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_19188\\3452088656.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_19188\\3452088656.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_df['IsAlone'].loc[combined_df['FamilySize'] > 1] = 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(r\"C:\\Kaggles\\Titanic\\Dataset\\train.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Kaggles\\Titanic\\Dataset\\test.csv\")\n",
    "\n",
    "# Combine train and test datasets to handle them together\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "# Feature Engineering\n",
    "for dataset in combine:\n",
    "    # Create new feature FamilySize\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    # Create new feature IsAlone\n",
    "    dataset['IsAlone'] = 1\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0\n",
    "    # Extract titles from names\n",
    "    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "                                                'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# Fill missing values\n",
    "for dataset in combine:\n",
    "    dataset['Age'].fillna(dataset['Age'].median(), inplace=True)\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace=True)\n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace=True)\n",
    "\n",
    "# Combine datasets for preprocessing\n",
    "test_df['Survived'] = np.nan  # Add a dummy 'Survived' column to align columns\n",
    "combined_df = pd.concat([train_df, test_df])\n",
    "\n",
    "# Feature Engineering\n",
    "combined_df['FamilySize'] = combined_df['SibSp'] + combined_df['Parch'] + 1\n",
    "combined_df['IsAlone'] = 1\n",
    "combined_df['IsAlone'].loc[combined_df['FamilySize'] > 1] = 0\n",
    "combined_df['Title'] = combined_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "combined_df['Title'] = combined_df['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "combined_df['Title'] = combined_df['Title'].replace('Mlle', 'Miss')\n",
    "combined_df['Title'] = combined_df['Title'].replace('Ms', 'Miss')\n",
    "combined_df['Title'] = combined_df['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# Fill missing values\n",
    "combined_df['Age'].fillna(combined_df['Age'].median(), inplace=True)\n",
    "combined_df['Embarked'].fillna(combined_df['Embarked'].mode()[0], inplace=True)\n",
    "combined_df['Fare'].fillna(combined_df['Fare'].median(), inplace=True)\n",
    "\n",
    "# Convert categorical features to numeric\n",
    "combined_df['Sex'] = combined_df['Sex'].map({'female': 1, 'male': 0}).astype(int)\n",
    "combined_df['Title'] = combined_df['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}).astype(int)\n",
    "combined_df['Embarked'] = combined_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "\n",
    "# Drop unnecessary features\n",
    "combined_df = combined_df.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
    "\n",
    "# Separate back into train and test sets\n",
    "train_df = combined_df[combined_df['Survived'].notna()]\n",
    "test_df = combined_df[combined_df['Survived'].isna()].drop('Survived', axis=1)\n",
    "\n",
    "X_train_full = train_df.drop('Survived', axis=1)\n",
    "y_train_full = train_df['Survived']\n",
    "X_test = test_df.copy()\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.12, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the model\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Validation Accuracy: {accuracy}')\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test).astype(int)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": pd.read_csv(r\"C:\\Kaggles\\Titanic\\Dataset\\test.csv\")[\"PassengerId\"],\n",
    "    \"Survived\": predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(r\"C:\\Kaggles\\Titanic\\Submissions\\Submission_2.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
