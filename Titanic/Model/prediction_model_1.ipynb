{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><u><b><h1 style=\"color:Red;\">Titanic : Machine Learning from Disaster</u></b></h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Loading Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'C:\\Kaggles\\Titanic\\Dataset\\train.csv')\n",
    "df_test = pd.read_csv(r'C:\\Kaggles\\Titanic\\Dataset\\test.csv')\n",
    "test_ids = df_test[\"PassengerId\"]\n",
    "\n",
    "print(df_train.shape)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data Cleaning</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    data = data.drop([\"Ticket\", \"PassengerId\", \"Name\", \"Cabin\"], axis=1)\n",
    "    \n",
    "    cols = [\"SibSp\", \"Parch\", \"Fare\", \"Age\"]\n",
    "    for col in cols:\n",
    "        data[col].fillna(data[col].median(), inplace=True)\n",
    "        \n",
    "    data.Embarked.fillna(\"U\", inplace=True)\n",
    "    return data\n",
    "\n",
    "df_train = clean(df_train)\n",
    "df_test = clean(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Data cleaned up. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "categorical_columns = [\"Sex\", \"Embarked\"]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    df_train.loc[:, column] = le.fit_transform(df_train[column])\n",
    "    df_test.loc[:, column] = le.fit_transform(df_test[column])\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train.drop(\"Survived\", axis=\"columns\")\n",
    "Y = df_train[\"Survived\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.12, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=10000).fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>K-Flod Cross Validation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_split = ShuffleSplit(n_splits=10, test_size=0.12, random_state=False)\n",
    "KFold_score_LR = cross_val_score(LogisticRegression(max_iter=1000), X, Y, cv=cv_split)\n",
    "print(KFold_score_LR)\n",
    "print(\"\\nAverage Score : \", np.mean(KFold_score_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Grid Search CV </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : Here i have written this GridSearchCV for checking for different models ; but for SVC ; since different parameters are given hence this will take huge time to compile the results ; i have made some modifications now ; previously it took 15+ hrs for compilation ; hence don't run this ;)   XD !!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def find_best_model_using_gridsearchcv(X,y):\n",
    "    algos = {\n",
    "        'logistic_regression' : {\n",
    "            'model': LogisticRegression(max_iter=1000),\n",
    "            'params': {\n",
    "                'fit_intercept': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1,2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion' : [\"squared_error\", \"friedman_mse\"],\n",
    "                'splitter': ['best','random']\n",
    "            }\n",
    "        }, \n",
    "        'SVC':{\n",
    "            'model' : SVC(), \n",
    "            'params' : {\n",
    "                'C': [1, 10, 100],\n",
    "                'gamma': [0.1, 0.01, 0.001],\n",
    "                'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "            }\n",
    "        }, \n",
    "        'RandomForestRegressor' : {\n",
    "            'model' : RandomForestRegressor(),\n",
    "            'params' : {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [None, 5, 10, 20],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'max_features': ['sqrt', 'log2']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "    for algo_name, config in algos.items():\n",
    "        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        gs.fit(X,y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "\n",
    "find_best_model_using_gridsearchcv(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>It's clearly evident that using Logistic Regression is a better way to analyse this problem. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_preds = clf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"PassengerId\": test_ids.values,\n",
    "                   \"Survived\": submission_preds,\n",
    "                  })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Kaggles\\Titanic\\Submissions\\Submission_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
